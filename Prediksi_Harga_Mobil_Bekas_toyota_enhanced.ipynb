{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adc844e",
   "metadata": {},
   "source": [
    "\n",
    "# Prediksi Harga Mobil Bekas — E2E Workflow (EDA ➜ Modeling ➜ Ekspor `model.pkl`)\n",
    "Notebook ini menyajikan alur **mengalir** dari memahami data, **EDA**, pemodelan, evaluasi, hingga ekspor artefak untuk aplikasi Streamlit.\n",
    "Dataset yang dipakai: **`toyota.csv`** (harus berada **satu folder** dengan notebook).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e5d88a",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Persiapan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install -q pandas numpy scikit-learn matplotlib\n",
    "import os, json, pickle, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "print(\"Pustaka siap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ada31",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Muat Data & Pemahaman Awal\n",
    "Letakkan `toyota.csv` di folder yang sama. Atur kolom target (harga).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = \"toyota.csv\"          # terkunci ke file ini\n",
    "TARGET_COLUMN = \"price\"           # ganti jika perlu\n",
    "\n",
    "assert os.path.exists(DATA_PATH), \"File 'toyota.csv' harus berada satu folder dengan notebook.\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nInfo singkat:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nStatistik deskriptif (numerik):\")\n",
    "display(df.describe())\n",
    "\n",
    "# Deteksi tipe kolom\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "if TARGET_COLUMN in numeric_cols:\n",
    "    numeric_cols.remove(TARGET_COLUMN)\n",
    "\n",
    "print(\"\\nFitur numerik   :\", numeric_cols)\n",
    "print(\"Fitur kategorik :\", cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c760c26",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Data Quality Check\n",
    "Cek missing values, duplikasi, dan anomali sederhana.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b02b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Missing values\n",
    "na_counts = df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Jumlah missing values per kolom:\")\n",
    "display(na_counts)\n",
    "\n",
    "# Persentase missing\n",
    "na_pct = (df.isna().mean()*100).sort_values(ascending=False).round(2)\n",
    "print(\"Persentase missing (%):\")\n",
    "display(na_pct)\n",
    "\n",
    "# Duplikasi\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"Jumlah baris duplikat: {dup_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fee90",
   "metadata": {},
   "source": [
    "\n",
    "## 3. EDA: Univariate (Distribusi/Counts)\n",
    "- Numerik: histogram\n",
    "- Kategorikal: 10 kategori teratas berdasarkan frekuensi\n",
    "> **Catatan plotting:** Menggunakan **matplotlib** dan **satu plot per grafik**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527d0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hist numerik (satu plot per fitur)\n",
    "for col in numeric_cols + ([TARGET_COLUMN] if TARGET_COLUMN in df.columns and df[TARGET_COLUMN].dtype!='O' else []):\n",
    "    plt.figure()\n",
    "    df[col].dropna().hist(bins=30)\n",
    "    plt.title(f\"Distribusi: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frekuensi\")\n",
    "    plt.show()\n",
    "\n",
    "# Bar chart untuk kategorikal (top 10)\n",
    "for col in cat_cols:\n",
    "    vc = df[col].astype(str).value_counts().head(10)\n",
    "    plt.figure()\n",
    "    vc.plot(kind=\"bar\")\n",
    "    plt.title(f\"Top 10 Kategori: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Jumlah\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ab262",
   "metadata": {},
   "source": [
    "\n",
    "## 4. EDA: Korelasi Numerik\n",
    "Heatmap sederhana korelasi antar fitur numerik + target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_for_corr = numeric_cols.copy()\n",
    "if TARGET_COLUMN in df.columns and pd.api.types.is_numeric_dtype(df[TARGET_COLUMN]):\n",
    "    num_for_corr = num_for_corr + [TARGET_COLUMN]\n",
    "\n",
    "if len(num_for_corr) >= 2:\n",
    "    corr = df[num_for_corr].corr(numeric_only=True)\n",
    "    plt.figure()\n",
    "    plt.imshow(corr, interpolation='nearest')\n",
    "    plt.title(\"Korelasi (numerik)\")\n",
    "    plt.colorbar()\n",
    "    ticks = range(len(corr.columns))\n",
    "    plt.xticks(ticks, corr.columns, rotation=45, ha=\"right\")\n",
    "    plt.yticks(ticks, corr.columns)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Tidak cukup kolom numerik untuk korelasi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b176d",
   "metadata": {},
   "source": [
    "\n",
    "## 5. (Opsional) Pembersihan Sederhana\n",
    "Contoh langkah ringan: drop duplikasi. Langkah lain (outlier, imputasi) menyesuaikan kebutuhan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop duplikasi jika ada\n",
    "before = df.shape[0]\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "after = df.shape[0]\n",
    "print(f\"Baris sebelum/ sesudah drop duplicates: {before} -> {after}\")\n",
    "\n",
    "# Recompute tipe kolom setelah pembersihan\n",
    "numeric_cols = df.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()\n",
    "if TARGET_COLUMN in numeric_cols:\n",
    "    numeric_cols.remove(TARGET_COLUMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6453a494",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Split Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24548917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert TARGET_COLUMN in df.columns, f\"Kolom target '{TARGET_COLUMN}' tidak ditemukan.\"\n",
    "y = df[TARGET_COLUMN]\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ebfb5f",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Pipeline (Preprocess ➜ Model) & Training\n",
    "- Numerik: `StandardScaler`\n",
    "- Kategorikal: `OneHotEncoder(handle_unknown=\"ignore\")`\n",
    "- Model: `RandomForestRegressor`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4419b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "numeric_transformer = Pipeline([(\"scaler\", StandardScaler(with_mean=False))])\n",
    "categorical_transformer = Pipeline([(\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, X_train.select_dtypes(include=[\"number\"]).columns.tolist()),\n",
    "    (\"cat\", categorical_transformer, X_train.select_dtypes(include=[\"object\",\"category\",\"bool\"]).columns.tolist()),\n",
    "])\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "pipe = Pipeline([(\"preprocess\", preprocess), (\"model\", model)])\n",
    "pipe.fit(X_train, y_train)\n",
    "print(\"Training selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9481a",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Evaluasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_train = pipe.predict(X_train)\n",
    "pred_test  = pipe.predict(X_test)\n",
    "\n",
    "rmse_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "rmse_test  = mean_squared_error(y_test, pred_test, squared=False)\n",
    "mae_test   = mean_absolute_error(y_test, pred_test)\n",
    "r2_test    = r2_score(y_test, pred_test)\n",
    "\n",
    "print(f\"RMSE train: {rmse_train:.4f}\")\n",
    "print(f\"RMSE test : {rmse_test:.4f}\")\n",
    "print(f\"MAE test  : {mae_test:.4f}\")\n",
    "print(f\"R2  test  : {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f71c632",
   "metadata": {},
   "source": [
    "\n",
    "## 9. (Opsional) Pentingnya Fitur\n",
    "Tampilkan 20 fitur engineered (pasca One-Hot) paling penting menurut RandomForest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8708507",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ambil nama fitur setelah transformasi\n",
    "try:\n",
    "    feat_names = pipe.named_steps[\"preprocess\"].get_feature_names_out()\n",
    "except Exception:\n",
    "    # fallback: gunakan kolom asli (kurang akurat untuk OHE)\n",
    "    feat_names = pipe.named_steps[\"preprocess\"].transformers_[0][2] + pipe.named_steps[\"preprocess\"].transformers_[1][2]\n",
    "\n",
    "importances = pipe.named_steps[\"model\"].feature_importances_\n",
    "imp = pd.DataFrame({\"feature\": feat_names, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
    "display(imp.head(20))\n",
    "\n",
    "# Plot top 20 (satu plot)\n",
    "top = imp.head(20).iloc[::-1]  # balik biar bar chart dari kecil ke besar\n",
    "plt.figure()\n",
    "plt.barh(top[\"feature\"], top[\"importance\"])\n",
    "plt.title(\"Top 20 Feature Importance (engineered)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a09e7f",
   "metadata": {},
   "source": [
    "\n",
    "## 10. Ekspor Artefak\n",
    "- `model.pkl` — pipeline lengkap\n",
    "- `columns.json` — urutan kolom fitur mentah (sebelum transform)\n",
    "- `example_features.json` — 1 contoh baris untuk uji cepat di aplikasi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaae2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(pipe, f)\n",
    "\n",
    "with open(\"columns.json\", \"w\") as f:\n",
    "    json.dump(X.columns.tolist(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "example = X_train.iloc[0:1].to_dict(orient=\"records\")[0]\n",
    "with open(\"example_features.json\", \"w\") as f:\n",
    "    json.dump(example, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Disimpan: model.pkl, columns.json, example_features.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36652f2",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Verifikasi Artefak\n",
    "Muat `model.pkl` dan prediksi 1 baris.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"model.pkl\", \"rb\") as f:\n",
    "    loaded = pickle.load(f)\n",
    "\n",
    "pred_one = float(loaded.predict(X_test.iloc[0:1])[0])\n",
    "print(\"Prediksi 1 baris (sanity check):\", pred_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d9c8e",
   "metadata": {},
   "source": [
    "\n",
    "## 12. Lanjut ke Aplikasi Streamlit\n",
    "1) Pastikan file berikut berada di folder yang sama:\n",
    "   - `model.pkl`\n",
    "   - `columns.json`\n",
    "   - `streamlit_app_chat_car_price.py`  *(kode sudah disiapkan sebelumnya)*\n",
    "2) Set API key Gemini dan jalankan:\n",
    "```bash\n",
    "pip install streamlit google-generativeai scikit-learn pandas numpy\n",
    "export GEMINI_API_KEY=YOUR_KEY\n",
    "streamlit run streamlit_app_chat_car_price.py\n",
    "```\n",
    "Di sidebar aplikasi:\n",
    "- Upload `model.pkl` **atau** aktifkan \"Gunakan path lokal\".\n",
    "- Aktifkan **Gemini (LLM Chat)** untuk mode percakapan pakar.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
